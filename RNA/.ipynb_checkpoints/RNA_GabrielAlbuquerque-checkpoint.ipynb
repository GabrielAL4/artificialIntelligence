{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Redes Neurais Artificiais (RNA)\n",
    "\n",
    "### Redes neurais artificiais (RNAs) são modelos computacionais inspirados no funcionamento do cérebro humano. Elas são uma parte fundamental da inteligência artificial e do aprendizado de máquina. As RNAs são compostas por unidades chamadas neurônios artificiais, que são organizados em camadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui teremos a camada de configuração inicial, com importações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte utilizada para salvar imagens PNG do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"ann\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurônios Biológicos x RNA\n",
    "\n",
    "### A relação entre neurônios biológicos e artificiais reside na inspiração da arquitetura neural do cérebro humano para criar redes neurais artificiais (RNAs). Os neurônios artificiais são modelados com base na estrutura e função dos neurônios biológicos, realizando operações como soma ponderada e aplicação de funções de ativação. Ambos os sistemas compartilham o conceito de conexões neurais, embora as RNAs representem uma simplificação das complexidades presentes no cérebro. Apesar das semelhanças, as RNAs são projetadas para tarefas específicas e levantam desafios éticos e filosóficos, enquanto a pesquisa em neurociência e inteligência artificial continua a influenciar mutuamente esses campos interdisciplinares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "### O perceptron é um modelo simplificado de neurônio artificial, inicialmente proposto por Frank Rosenblatt em 1957. Ele é a unidade básica de uma rede neural e serve como bloco de construção fundamental para compreender conceitos mais avançados em aprendizado de máquina e inteligência artificial. O código abaixo utiliza o perceptron na sua implementação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Carrega o conjunto de dados Iris\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "# Seleciona duas características (comprimento e largura da pétala) para simplificar a tarefa\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "\n",
    "# Define a variável de destino binária, indicando se a flor é da espécie Iris setosa ou não\n",
    "y = (iris.target == 0)  # Iris setosa\n",
    "\n",
    "# Cria um classificador Perceptron\n",
    "per_clf = Perceptron(random_state=42)\n",
    "\n",
    "# Treina o Perceptron com as características e a variável de destino\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "# Define novas instâncias de dados para predição\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "\n",
    "# Realiza predições usando o modelo treinado\n",
    "y_pred = per_clf.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs\n",
    "\n",
    "### Neste trecho, é criado um modelo sequencial usando a API Keras. O modelo consiste em uma camada de entrada, uma camada de achatamento (flatten) para transformar imagens 28x28 em um vetor unidimensional, duas camadas densas (totalizando 300 e 100 neurônios, respectivamente) com ativação ReLU, e uma camada de saída com 10 neurônios (um para cada classe no conjunto de dados MNIST) e ativação softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.reshaping.flatten.Flatten at 0x7f693067c050>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7f68f042c090>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7f68f0417d50>,\n",
       " <keras.src.layers.core.dense.Dense at 0x7f68f0426910>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este trecho explora informações sobre a primeira camada oculta do modelo (camada de achatamento). Ele acessa a camada pelo índice e pelo nome, verifica se a camada 'dense' está na lista de camadas do modelo, e obtém os pesos e vieses da camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: dense. Existing layers are: ['flatten_3', 'dense_9', 'dense_10', 'dense_11'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m hidden1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m hidden1\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m hidden1\n\u001b[1;32m      6\u001b[0m weights, biases \u001b[38;5;241m=\u001b[39m hidden1\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m      7\u001b[0m weights\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3567\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3565\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   3566\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 3567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3568\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3569\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3570\u001b[0m     )\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3573\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: dense. Existing layers are: ['flatten_3', 'dense_9', 'dense_10', 'dense_11']."
     ]
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name\n",
    "\n",
    "model.get_layer('dense') is hidden1\n",
    "\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights\n",
    "\n",
    "weights.shape\n",
    "\n",
    "biases\n",
    "\n",
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neste trecho, o modelo é compilado com uma função de perda (sparse_categorical_crossentropy), um otimizador (sgd - gradiente descendente estocástico) e métricas (accuracy). Em seguida, o modelo é treinado usando os dados de treinamento (X_train, y_train) por 30 épocas, e a validação é realizada usando o conjunto de validação (X_valid, y_valid). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O histórico do treinamento é armazenado na variável history. Este histórico pode ser usado posteriormente para visualizar as métricas de treinamento e validação ao longo das épocas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
